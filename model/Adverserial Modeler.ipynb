{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import time\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to dictionaries to embed\n",
    "\n",
    "class Factors():\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {}\n",
    "        self.ind2tok = {}\n",
    "    \n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "    \n",
    "# boiler plate code for general sentences but works for our purposes too\n",
    "def build_factors(examples):\n",
    "    counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        counts.update(words)\n",
    "    \n",
    "    word_list = [w for w in counts if counts[w] > 1]\n",
    "    \n",
    "    word_dict = Vocabulary()\n",
    "    for w in word_list:\n",
    "        word_dict.add(w)\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 526 train samples\n",
      "Read 176 test samples\n",
      "[[ nan  nan  nan ... 4.   1.   3.  ]\n",
      " [ nan  nan  nan ... 4.   1.   4.  ]\n",
      " [ nan 3.01  nan ... 4.   1.   0.  ]\n",
      " ...\n",
      " [ nan  nan  nan ... 1.   1.   2.  ]\n",
      " [ nan  nan  nan ... 4.   1.   1.  ]\n",
      " [ nan  nan  nan ... 4.   1.   2.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Data Reader Class\n",
    "\n",
    "class DataReader(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Read in dataframe with proper headers and col dtypes, and remove dups\n",
    "        self.train_data = pd.read_csv(\"train.csv\", nrows = 50000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        self.test_data = pd.read_csv(\"test.csv\", nrows = 1000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        \n",
    "        cats = [\"state_abbr\", \"purchaser_type_name\", \"property_type_name\", \"preapproval_name\",\n",
    "                \"owner_occupancy_name\", \"msamd_name\", \"loan_type_name\", \"loan_purpose_name\",\n",
    "                \"lien_status_name\", \"hoepa_status_name\", \"denial_reason_name_1\",\"denial_reason_name_2\",\n",
    "                \"county_name\", \"co_applicant_sex_name\", \"co_applicant_race_name_1\",\n",
    "                \"co_applicant_ethnicity_name\", \"applicant_sex_name\", \"applicant_race_name_1\",\n",
    "                \"applicant_ethnicity_name\", \"agency_abbr\", \"approved\", \"denial_reason_name_3\"]\n",
    "        \n",
    "        # convert categorical strings to classes\n",
    "        for cat in cats:\n",
    "            self.train_data[cat] = pd.Categorical(self.train_data[cat]).codes\n",
    "            self.test_data[cat] = pd.Categorical(self.test_data[cat]).codes\n",
    "\n",
    "        self.train_x = np.asarray(self.train_data.iloc[:, 0:-1], dtype = np.float64)\n",
    "        self.train_y = np.asarray(self.train_data.iloc[:, -1],dtype = np.float64 )\n",
    "        print(\"Read %d train samples\" % len(self.train_y))\n",
    "\n",
    "\n",
    "        self.test_x = np.asarray(self.test_data.iloc[:, 0:-1], dtype = np.float64)\n",
    "        self.test_y = np.asarray(self.test_data.iloc[:, -1], dtype = np.float64)\n",
    "        print(\"Read %d test samples\" % len(self.test_y))\n",
    "\n",
    "        \n",
    "        # get meta\n",
    "        self.num_classes = 2\n",
    "        self.input_size = self.train_x.shape[1]\n",
    "        self.indexes = list(range(len(self.train_y)))\n",
    "        self.train_size = len(self.train_y)\n",
    "        \n",
    "    def inputSize(self):\n",
    "        return self.input_size\n",
    "\n",
    "    def init(self, batch_size):\n",
    "        # shuffle\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return int(math.ceil(self.train_size / float(batch_size)))\n",
    "\n",
    "    def get_batch(self, i):\n",
    "        selected_idx = self.indexes[i*self.batch_size : (i+1)*self.batch_size]\n",
    "        return self.train_x[selected_idx, :], self.train_y[selected_idx]\n",
    "\n",
    "df = DataReader()\n",
    "print(df.train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        var_x = Variable(torch.from_numpy(x).float())\n",
    "        logitis = self.fc2(self.non_linear(self.fc1(var_x)))\n",
    "        return nn.functional.log_softmax(logitis, dim=1)\n",
    "\n",
    "# a = np.array([[70.1100006103516,np.nan,7966.0,34.6800003051758, 937.0, 1721.0, 143.0, 67500.0,\n",
    "#  30.0, 43, np.nan,7, 2, 1, 2, 259, 1, 1, 1, 1, np.nan, np.nan, -1, 1262, 2,4, 2, 414.03, 2017, 1, 4, 1, 3],\n",
    "#  [93.47000122070308, 1.99, 6441.0, 100.0, 1547.0, 2727.0, 52.0, 18000.0, 29.0, 39,\n",
    "#   np.nan, 1, 2, 0, 2, 155, 1, 1, 1, 1, np.nan, np.nan, -1, 1121, 0, 6, 0, 2902.0, 2017, 1, 4, 0, 3,]])\n",
    "# t = Variable(torch.from_numpy(a))\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_x, data_y, model, loss_func, name):\n",
    "    model.eval()\n",
    "    log_py = model(data_x)\n",
    "    y = Variable(torch.from_numpy(data_y).long())\n",
    "    l = loss_func(log_py, y).item()\n",
    "    \n",
    "    pred = np.argmax(log_py.data.numpy(), axis=1)\n",
    "    acc = np.mean(pred == data_y)\n",
    "    print(\"%s loss %f and acc %f \" % (name, l, acc))\n",
    "    return l, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 526 train samples\n",
      "Read 176 test samples\n",
      "Epoch 0\n",
      "TRAIN loss 0.263381 and acc 1.000000 \n",
      "TEST loss 0.263379 and acc 1.000000 \n",
      "Epoch 1\n",
      "TRAIN loss 0.150607 and acc 1.000000 \n",
      "TEST loss 0.150606 and acc 1.000000 \n",
      "Epoch 2\n",
      "TRAIN loss 0.103322 and acc 1.000000 \n",
      "TEST loss 0.103323 and acc 1.000000 \n",
      "Epoch 3\n",
      "TRAIN loss 0.078040 and acc 1.000000 \n",
      "TEST loss 0.078039 and acc 1.000000 \n",
      "Epoch 4\n",
      "TRAIN loss 0.062475 and acc 1.000000 \n",
      "TEST loss 0.062474 and acc 1.000000 \n",
      "Epoch 5\n",
      "TRAIN loss 0.051985 and acc 1.000000 \n",
      "TEST loss 0.051985 and acc 1.000000 \n",
      "Epoch 6\n",
      "TRAIN loss 0.044460 and acc 1.000000 \n",
      "TEST loss 0.044460 and acc 1.000000 \n",
      "Epoch 7\n",
      "TRAIN loss 0.038809 and acc 1.000000 \n",
      "TEST loss 0.038809 and acc 1.000000 \n",
      "Epoch 8\n",
      "TRAIN loss 0.034415 and acc 1.000000 \n",
      "TEST loss 0.034415 and acc 1.000000 \n",
      "Epoch 9\n",
      "TRAIN loss 0.030904 and acc 1.000000 \n",
      "TEST loss 0.030904 and acc 1.000000 \n",
      "Epoch 10\n",
      "TRAIN loss 0.028035 and acc 1.000000 \n",
      "TEST loss 0.028035 and acc 1.000000 \n",
      "Epoch 11\n",
      "TRAIN loss 0.025649 and acc 1.000000 \n",
      "TEST loss 0.025649 and acc 1.000000 \n",
      "Epoch 12\n",
      "TRAIN loss 0.023633 and acc 1.000000 \n",
      "TEST loss 0.023633 and acc 1.000000 \n",
      "Epoch 13\n",
      "TRAIN loss 0.021908 and acc 1.000000 \n",
      "TEST loss 0.021908 and acc 1.000000 \n",
      "Epoch 14\n",
      "TRAIN loss 0.020416 and acc 1.000000 \n",
      "TEST loss 0.020416 and acc 1.000000 \n",
      "Epoch 15\n",
      "TRAIN loss 0.019113 and acc 1.000000 \n",
      "TEST loss 0.019113 and acc 1.000000 \n",
      "Epoch 16\n",
      "TRAIN loss 0.017965 and acc 1.000000 \n",
      "TEST loss 0.017965 and acc 1.000000 \n",
      "Epoch 17\n",
      "TRAIN loss 0.016946 and acc 1.000000 \n",
      "TEST loss 0.016946 and acc 1.000000 \n",
      "Epoch 18\n",
      "TRAIN loss 0.016036 and acc 1.000000 \n",
      "TEST loss 0.016036 and acc 1.000000 \n",
      "Epoch 19\n",
      "TRAIN loss 0.015218 and acc 1.000000 \n",
      "TEST loss 0.015218 and acc 1.000000 \n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.0\n",
    "L2_DECAY = 0.0\n",
    "\n",
    "data_loader = DataReader()\n",
    "model = FNN(data_loader.inputSize(), hidden_size=300, output_size=2)\n",
    "nll_loss = nn.NLLLoss()\n",
    "op = torch.optim.SGD(model.parameters(), lr=LR, \n",
    "                     momentum=MOMENTUM, weight_decay=L2_DECAY)\n",
    "\n",
    "train_metric, test_metric = [], []\n",
    "for i in range(NUM_EPOCH):\n",
    "    print(\"Epoch %d\" % i)\n",
    "    num_batches = data_loader.init(batch_size=BATCH_SIZE)\n",
    "    model.train()\n",
    "    for b in range(num_batches):\n",
    "        x, y = data_loader.get_batch(b)\n",
    "        pred_y = model(x)\n",
    "        y = Variable(torch.from_numpy(y).long())\n",
    "        loss = nll_loss(pred_y, y)\n",
    "        op.zero_grad()\n",
    "        loss.backward()\n",
    "        op.step()\n",
    "\n",
    "    train_metric.append(eval(data_loader.train_x, data_loader.train_y, model, nll_loss, \"TRAIN\"))\n",
    "    test_metric.append(eval(data_loader.test_x, data_loader.test_y, model, nll_loss, \"TEST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
