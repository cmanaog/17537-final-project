{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import time\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to dictionaries to embed\n",
    "\n",
    "class Factors():\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {}\n",
    "        self.ind2tok = {}\n",
    "    \n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "    \n",
    "# boiler plate code for general sentences but works for our purposes too\n",
    "def build_factors(examples):\n",
    "    counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        counts.update(words)\n",
    "    \n",
    "    word_list = [w for w in counts if counts[w] > 1]\n",
    "    \n",
    "    word_dict = Vocabulary()\n",
    "    for w in word_list:\n",
    "        word_dict.add(w)\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 50000 train samples\n",
      "Read 1000 test samples\n",
      "[nan nan nan nan nan nan 51.0 nan 62.0 41 nan 7 0 0 2 -1 0 1 1 1 nan nan -1\n",
      " -1 0 6 3 nan 2017 1 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Data Reader Class\n",
    "\n",
    "class DataReader(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Read in dataframe with proper headers and col dtypes, and remove dups\n",
    "        self.train_data = pd.read_csv(\"train.csv\", nrows = 50000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        self.test_data = pd.read_csv(\"test.csv\", nrows = 1000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        cats = [\"state_abbr\", \"purchaser_type_name\", \"property_type_name\", \"preapproval_name\",\n",
    "                \"owner_occupancy_name\", \"msamd_name\", \"loan_type_name\", \"loan_purpose_name\",\n",
    "                \"lien_status_name\", \"hoepa_status_name\", \"denial_reason_name_1\", \"county_name\",\n",
    "                \"co_applicant_sex_name\", \"co_applicant_race_name_1\", \"co_applicant_ethnicity_name\",\n",
    "                \"applicant_sex_name\", \"applicant_race_name_1\", \"applicant_ethnicity_name\", \"agency_abbr\",\n",
    "                \"approved\"]\n",
    "        \n",
    "        # convert categorical strings to classes\n",
    "        for cat in cats:\n",
    "            self.train_data[cat] = pd.Categorical(self.train_data[cat]).codes\n",
    "            self.test_data[cat] = pd.Categorical(self.test_data[cat]).codes\n",
    "\n",
    "        self.train_x = np.asarray(self.train_data.iloc[:, 0:-1])\n",
    "        self.train_y = np.asarray(self.train_data.iloc[:, -1])\n",
    "        print(\"Read %d train samples\" % len(self.train_y))\n",
    "\n",
    "\n",
    "        self.test_x = np.asarray(self.test_data.iloc[:, 0:-1])\n",
    "        self.test_y = np.asarray(self.test_data.iloc[:, -1])\n",
    "        print(\"Read %d test samples\" % len(self.test_y))\n",
    "\n",
    "        \n",
    "        # get meta\n",
    "        self.num_classes = 2\n",
    "        self.input_size = self.train_x.shape[1]\n",
    "        self.indexes = list(range(len(self.train_y)))\n",
    "        self.train_size = len(self.train_y)\n",
    "        \n",
    "    def inputSize(self):\n",
    "        return self.input_size\n",
    "\n",
    "    def init(self, batch_size):\n",
    "        # shuffle\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return int(math.ceil(self.train_size / float(batch_size)))\n",
    "\n",
    "    def get_batch(self, i):\n",
    "        selected_idx = self.indexes[i*self.batch_size : (i+1)*self.batch_size]\n",
    "        return self.train_x[selected_idx, :], self.train_y[selected_idx]\n",
    "\n",
    "df = DataReader()\n",
    "print(df.train_x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        var_x = Variable(torch.from_numpy(x).float())\n",
    "        logitis = self.fc2(self.non_linear(self.fc1(var_x)))\n",
    "        return nn.functional.log_softmax(logitis, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(data_x, data_y, model, loss_func, name):\n",
    "    model.eval()\n",
    "    log_py = model(data_x)\n",
    "    y = Variable(torch.from_numpy(data_y).long())\n",
    "    l = loss_func(log_py, y).item()\n",
    "    \n",
    "    pred = np.argmax(log_py.data.numpy(), axis=1)\n",
    "    acc = np.mean(pred == data_y)\n",
    "    print(\"%s loss %f and acc %f \" % (name, l, acc))\n",
    "    return l, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 50000 train samples\n",
      "Read 1000 test samples\n",
      "Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "can't convert a given np.ndarray to a tensor - it has an invalid type. The only supported types are: double, float, int64, int32, and uint8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-af939335cbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shared/anaconda/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-32e9167eb5bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mlogitis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogitis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: can't convert a given np.ndarray to a tensor - it has an invalid type. The only supported types are: double, float, int64, int32, and uint8."
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.0\n",
    "L2_DECAY = 0.0\n",
    "\n",
    "data_loader = DataReader()\n",
    "model = FNN(data_loader.inputSize(), hidden_size=300, output_size=2)\n",
    "nll_loss = nn.NLLLoss()\n",
    "op = torch.optim.SGD(model.parameters(), lr=LR, \n",
    "                     momentum=MOMENTUM, weight_decay=L2_DECAY)\n",
    "\n",
    "train_metric, test_metric = [], []\n",
    "for i in range(NUM_EPOCH):\n",
    "    print(\"Epoch %d\" % i)\n",
    "    num_batches = data_loader.init(batch_size=BATCH_SIZE)\n",
    "    model.train()\n",
    "    for b in range(num_batches):\n",
    "        x, y = data_loader.get_batch(b)\n",
    "        pred_y = model(x)\n",
    "        y = Variable(torch.from_numpy(y).long())\n",
    "        loss = nll_loss(pred_y, y)\n",
    "        op.zero_grad()\n",
    "        loss.backward()\n",
    "        op.step()\n",
    "\n",
    "    train_metric.append(eval(data_loader.train_x, data_loader.train_y, model, nll_loss, \"TRAIN\"))\n",
    "    dev_metric.append(eval(data_loader.dev_x, data_loader.dev_y, model, nll_loss, \"TEST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
