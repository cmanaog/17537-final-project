{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import time\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to dictionaries to embed\n",
    "\n",
    "class Factors():\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {}\n",
    "        self.ind2tok = {}\n",
    "    \n",
    "    def add(self, token):\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "    \n",
    "    def get_index(self, word):\n",
    "        if word in self.tok2ind:\n",
    "            return self.tok2ind[word]\n",
    "        return self.tok2ind[self.UNKNOWN]\n",
    "    \n",
    "    def get_word(self, i):\n",
    "        return self.ind2tok[i]\n",
    "\n",
    "    def sentence_to_indices(self, sentence):\n",
    "        words = [x for x in sentence.split(' ')]\n",
    "        indices = [self.get_index(w) for w in words]\n",
    "        return indices\n",
    "    \n",
    "# boiler plate code for general sentences but works for our purposes too\n",
    "def build_factors(examples):\n",
    "    counts = Counter()\n",
    "    for ex in examples:\n",
    "        words = [w for w in ex.split(' ') if w.strip()]\n",
    "        counts.update(words)\n",
    "    \n",
    "    word_list = [w for w in counts if counts[w] > 1]\n",
    "    \n",
    "    word_dict = Vocabulary()\n",
    "    for w in word_list:\n",
    "        word_dict.add(w)\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 526 train samples\n",
      "Read 176 test samples\n",
      "[[ nan  nan  nan ... 4.   1.   3.  ]\n",
      " [ nan  nan  nan ... 4.   1.   4.  ]\n",
      " [ nan 3.01  nan ... 4.   1.   0.  ]\n",
      " ...\n",
      " [ nan  nan  nan ... 1.   1.   2.  ]\n",
      " [ nan  nan  nan ... 4.   1.   1.  ]\n",
      " [ nan  nan  nan ... 4.   1.   2.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Data Reader Class\n",
    "\n",
    "class DataReader(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Read in dataframe with proper headers and col dtypes, and remove dups\n",
    "        self.train_data = pd.read_csv(\"train.csv\", nrows = 50000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        self.test_data = pd.read_csv(\"test.csv\", nrows = 1000, index_col = 0).drop([\"action_taken_name\",\n",
    "                                                                                      \"agency_name\",\n",
    "                                                                                      \"state_name\"], axis = 1)\n",
    "        \n",
    "        cats = [\"state_abbr\", \"purchaser_type_name\", \"property_type_name\", \"preapproval_name\",\n",
    "                \"owner_occupancy_name\", \"msamd_name\", \"loan_type_name\", \"loan_purpose_name\",\n",
    "                \"lien_status_name\", \"hoepa_status_name\", \"denial_reason_name_1\",\"denial_reason_name_2\",\n",
    "                \"county_name\", \"co_applicant_sex_name\", \"co_applicant_race_name_1\",\n",
    "                \"co_applicant_ethnicity_name\", \"applicant_sex_name\", \"applicant_race_name_1\",\n",
    "                \"applicant_ethnicity_name\", \"agency_abbr\", \"approved\", \"denial_reason_name_3\"]\n",
    "        \n",
    "        # convert categorical strings to classes\n",
    "        for cat in cats:\n",
    "            self.train_data[cat] = pd.Categorical(self.train_data[cat]).codes\n",
    "            self.test_data[cat] = pd.Categorical(self.test_data[cat]).codes\n",
    "\n",
    "        self.train_x = np.asarray(self.train_data.iloc[:, 0:-1], dtype = np.float64)\n",
    "        self.train_y = np.asarray(self.train_data.iloc[:, -1],dtype = np.float64 )\n",
    "        print(\"Read %d train samples\" % len(self.train_y))\n",
    "\n",
    "\n",
    "        self.test_x = np.asarray(self.test_data.iloc[:, 0:-1], dtype = np.float64)\n",
    "        self.test_y = np.asarray(self.test_data.iloc[:, -1], dtype = np.float64)\n",
    "        print(\"Read %d test samples\" % len(self.test_y))\n",
    "\n",
    "        \n",
    "        # get meta\n",
    "        self.num_classes = 2\n",
    "        self.input_size = self.train_x.shape[1]\n",
    "        self.indexes = list(range(len(self.train_y)))\n",
    "        self.train_size = len(self.train_y)\n",
    "        \n",
    "    def inputSize(self):\n",
    "        return self.input_size\n",
    "\n",
    "    def init(self, batch_size):\n",
    "        # shuffle\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return int(math.ceil(self.train_size / float(batch_size)))\n",
    "\n",
    "    def get_batch(self, i):\n",
    "        selected_idx = self.indexes[i*self.batch_size : (i+1)*self.batch_size]\n",
    "        return self.train_x[selected_idx, :], self.train_y[selected_idx]\n",
    "\n",
    "df = DataReader()\n",
    "print(df.train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        var_x = Variable(torch.from_numpy(x).float())\n",
    "        logitis = self.fc2(self.non_linear(self.fc1(var_x)))\n",
    "        return nn.functional.log_softmax(logitis, dim=1)\n",
    "\n",
    "# a = np.array([[70.1100006103516,np.nan,7966.0,34.6800003051758, 937.0, 1721.0, 143.0, 67500.0,\n",
    "#  30.0, 43, np.nan,7, 2, 1, 2, 259, 1, 1, 1, 1, np.nan, np.nan, -1, 1262, 2,4, 2, 414.03, 2017, 1, 4, 1, 3],\n",
    "#  [93.47000122070308, 1.99, 6441.0, 100.0, 1547.0, 2727.0, 52.0, 18000.0, 29.0, 39,\n",
    "#   np.nan, 1, 2, 0, 2, 155, 1, 1, 1, 1, np.nan, np.nan, -1, 1121, 0, 6, 0, 2902.0, 2017, 1, 4, 0, 3,]])\n",
    "# t = Variable(torch.from_numpy(a))\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_x, data_y, model, loss_func, name):\n",
    "    model.eval()\n",
    "    log_py = model(data_x)\n",
    "    y = Variable(torch.from_numpy(data_y).long())\n",
    "    l = loss_func(log_py, y).item()\n",
    "    \n",
    "    pred = np.argmax(log_py.data.numpy(), axis=1)\n",
    "    acc = np.mean(pred == data_y)\n",
    "    print(\"%s loss %f and acc %f \" % (name, l, acc))\n",
    "    return l, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 526 train samples\n",
      "Read 176 test samples\n",
      "Epoch 0\n",
      "TRAIN loss 0.269150 and acc 1.000000 \n",
      "TEST loss 0.269151 and acc 1.000000 \n",
      "Epoch 1\n",
      "TRAIN loss 0.152685 and acc 1.000000 \n",
      "TEST loss 0.152685 and acc 1.000000 \n",
      "Epoch 2\n",
      "TRAIN loss 0.104340 and acc 1.000000 \n",
      "TEST loss 0.104341 and acc 1.000000 \n",
      "Epoch 3\n",
      "TRAIN loss 0.078632 and acc 1.000000 \n",
      "TEST loss 0.078632 and acc 1.000000 \n",
      "Epoch 4\n",
      "TRAIN loss 0.062859 and acc 1.000000 \n",
      "TEST loss 0.062860 and acc 1.000000 \n",
      "Epoch 5\n",
      "TRAIN loss 0.052254 and acc 1.000000 \n",
      "TEST loss 0.052254 and acc 1.000000 \n",
      "Epoch 6\n",
      "TRAIN loss 0.044658 and acc 1.000000 \n",
      "TEST loss 0.044658 and acc 1.000000 \n",
      "Epoch 7\n",
      "TRAIN loss 0.038961 and acc 1.000000 \n",
      "TEST loss 0.038961 and acc 1.000000 \n",
      "Epoch 8\n",
      "TRAIN loss 0.034535 and acc 1.000000 \n",
      "TEST loss 0.034535 and acc 1.000000 \n",
      "Epoch 9\n",
      "TRAIN loss 0.031000 and acc 1.000000 \n",
      "TEST loss 0.031001 and acc 1.000000 \n",
      "Epoch 10\n",
      "TRAIN loss 0.028115 and acc 1.000000 \n",
      "TEST loss 0.028115 and acc 1.000000 \n",
      "Epoch 11\n",
      "TRAIN loss 0.025716 and acc 1.000000 \n",
      "TEST loss 0.025716 and acc 1.000000 \n",
      "Epoch 12\n",
      "TRAIN loss 0.023690 and acc 1.000000 \n",
      "TEST loss 0.023690 and acc 1.000000 \n",
      "Epoch 13\n",
      "TRAIN loss 0.021957 and acc 1.000000 \n",
      "TEST loss 0.021957 and acc 1.000000 \n",
      "Epoch 14\n",
      "TRAIN loss 0.020459 and acc 1.000000 \n",
      "TEST loss 0.020459 and acc 1.000000 \n",
      "Epoch 15\n",
      "TRAIN loss 0.019150 and acc 1.000000 \n",
      "TEST loss 0.019150 and acc 1.000000 \n",
      "Epoch 16\n",
      "TRAIN loss 0.017998 and acc 1.000000 \n",
      "TEST loss 0.017998 and acc 1.000000 \n",
      "Epoch 17\n",
      "TRAIN loss 0.016975 and acc 1.000000 \n",
      "TEST loss 0.016975 and acc 1.000000 \n",
      "Epoch 18\n",
      "TRAIN loss 0.016062 and acc 1.000000 \n",
      "TEST loss 0.016062 and acc 1.000000 \n",
      "Epoch 19\n",
      "TRAIN loss 0.015242 and acc 1.000000 \n",
      "TEST loss 0.015241 and acc 1.000000 \n",
      "Epoch 20\n",
      "TRAIN loss 0.014500 and acc 1.000000 \n",
      "TEST loss 0.014500 and acc 1.000000 \n",
      "Epoch 21\n",
      "TRAIN loss 0.013827 and acc 1.000000 \n",
      "TEST loss 0.013827 and acc 1.000000 \n",
      "Epoch 22\n",
      "TRAIN loss 0.013213 and acc 1.000000 \n",
      "TEST loss 0.013213 and acc 1.000000 \n",
      "Epoch 23\n",
      "TRAIN loss 0.012651 and acc 1.000000 \n",
      "TEST loss 0.012651 and acc 1.000000 \n",
      "Epoch 24\n",
      "TRAIN loss 0.012135 and acc 1.000000 \n",
      "TEST loss 0.012135 and acc 1.000000 \n",
      "Epoch 25\n",
      "TRAIN loss 0.011659 and acc 1.000000 \n",
      "TEST loss 0.011659 and acc 1.000000 \n",
      "Epoch 26\n",
      "TRAIN loss 0.011219 and acc 1.000000 \n",
      "TEST loss 0.011219 and acc 1.000000 \n",
      "Epoch 27\n",
      "TRAIN loss 0.010811 and acc 1.000000 \n",
      "TEST loss 0.010811 and acc 1.000000 \n",
      "Epoch 28\n",
      "TRAIN loss 0.010431 and acc 1.000000 \n",
      "TEST loss 0.010431 and acc 1.000000 \n",
      "Epoch 29\n",
      "TRAIN loss 0.010077 and acc 1.000000 \n",
      "TEST loss 0.010077 and acc 1.000000 \n",
      "Epoch 30\n",
      "TRAIN loss 0.009746 and acc 1.000000 \n",
      "TEST loss 0.009746 and acc 1.000000 \n",
      "Epoch 31\n",
      "TRAIN loss 0.009436 and acc 1.000000 \n",
      "TEST loss 0.009436 and acc 1.000000 \n",
      "Epoch 32\n",
      "TRAIN loss 0.009145 and acc 1.000000 \n",
      "TEST loss 0.009145 and acc 1.000000 \n",
      "Epoch 33\n",
      "TRAIN loss 0.008871 and acc 1.000000 \n",
      "TEST loss 0.008871 and acc 1.000000 \n",
      "Epoch 34\n",
      "TRAIN loss 0.008614 and acc 1.000000 \n",
      "TEST loss 0.008614 and acc 1.000000 \n",
      "Epoch 35\n",
      "TRAIN loss 0.008370 and acc 1.000000 \n",
      "TEST loss 0.008370 and acc 1.000000 \n",
      "Epoch 36\n",
      "TRAIN loss 0.008141 and acc 1.000000 \n",
      "TEST loss 0.008141 and acc 1.000000 \n",
      "Epoch 37\n",
      "TRAIN loss 0.007923 and acc 1.000000 \n",
      "TEST loss 0.007923 and acc 1.000000 \n",
      "Epoch 38\n",
      "TRAIN loss 0.007716 and acc 1.000000 \n",
      "TEST loss 0.007716 and acc 1.000000 \n",
      "Epoch 39\n",
      "TRAIN loss 0.007520 and acc 1.000000 \n",
      "TEST loss 0.007520 and acc 1.000000 \n",
      "Epoch 40\n",
      "TRAIN loss 0.007334 and acc 1.000000 \n",
      "TEST loss 0.007334 and acc 1.000000 \n",
      "Epoch 41\n",
      "TRAIN loss 0.007157 and acc 1.000000 \n",
      "TEST loss 0.007157 and acc 1.000000 \n",
      "Epoch 42\n",
      "TRAIN loss 0.006988 and acc 1.000000 \n",
      "TEST loss 0.006988 and acc 1.000000 \n",
      "Epoch 43\n",
      "TRAIN loss 0.006827 and acc 1.000000 \n",
      "TEST loss 0.006827 and acc 1.000000 \n",
      "Epoch 44\n",
      "TRAIN loss 0.006673 and acc 1.000000 \n",
      "TEST loss 0.006673 and acc 1.000000 \n",
      "Epoch 45\n",
      "TRAIN loss 0.006526 and acc 1.000000 \n",
      "TEST loss 0.006526 and acc 1.000000 \n",
      "Epoch 46\n",
      "TRAIN loss 0.006385 and acc 1.000000 \n",
      "TEST loss 0.006385 and acc 1.000000 \n",
      "Epoch 47\n",
      "TRAIN loss 0.006250 and acc 1.000000 \n",
      "TEST loss 0.006250 and acc 1.000000 \n",
      "Epoch 48\n",
      "TRAIN loss 0.006120 and acc 1.000000 \n",
      "TEST loss 0.006120 and acc 1.000000 \n",
      "Epoch 49\n",
      "TRAIN loss 0.005996 and acc 1.000000 \n",
      "TEST loss 0.005996 and acc 1.000000 \n",
      "Epoch 50\n",
      "TRAIN loss 0.005877 and acc 1.000000 \n",
      "TEST loss 0.005877 and acc 1.000000 \n",
      "Epoch 51\n",
      "TRAIN loss 0.005763 and acc 1.000000 \n",
      "TEST loss 0.005763 and acc 1.000000 \n",
      "Epoch 52\n",
      "TRAIN loss 0.005652 and acc 1.000000 \n",
      "TEST loss 0.005652 and acc 1.000000 \n",
      "Epoch 53\n",
      "TRAIN loss 0.005546 and acc 1.000000 \n",
      "TEST loss 0.005546 and acc 1.000000 \n",
      "Epoch 54\n",
      "TRAIN loss 0.005444 and acc 1.000000 \n",
      "TEST loss 0.005444 and acc 1.000000 \n",
      "Epoch 55\n",
      "TRAIN loss 0.005346 and acc 1.000000 \n",
      "TEST loss 0.005346 and acc 1.000000 \n",
      "Epoch 56\n",
      "TRAIN loss 0.005251 and acc 1.000000 \n",
      "TEST loss 0.005251 and acc 1.000000 \n",
      "Epoch 57\n",
      "TRAIN loss 0.005159 and acc 1.000000 \n",
      "TEST loss 0.005159 and acc 1.000000 \n",
      "Epoch 58\n",
      "TRAIN loss 0.005070 and acc 1.000000 \n",
      "TEST loss 0.005070 and acc 1.000000 \n",
      "Epoch 59\n",
      "TRAIN loss 0.004985 and acc 1.000000 \n",
      "TEST loss 0.004985 and acc 1.000000 \n",
      "Epoch 60\n",
      "TRAIN loss 0.004902 and acc 1.000000 \n",
      "TEST loss 0.004902 and acc 1.000000 \n",
      "Epoch 61\n",
      "TRAIN loss 0.004822 and acc 1.000000 \n",
      "TEST loss 0.004822 and acc 1.000000 \n",
      "Epoch 62\n",
      "TRAIN loss 0.004745 and acc 1.000000 \n",
      "TEST loss 0.004745 and acc 1.000000 \n",
      "Epoch 63\n",
      "TRAIN loss 0.004670 and acc 1.000000 \n",
      "TEST loss 0.004670 and acc 1.000000 \n",
      "Epoch 64\n",
      "TRAIN loss 0.004597 and acc 1.000000 \n",
      "TEST loss 0.004597 and acc 1.000000 \n",
      "Epoch 65\n",
      "TRAIN loss 0.004527 and acc 1.000000 \n",
      "TEST loss 0.004527 and acc 1.000000 \n",
      "Epoch 66\n",
      "TRAIN loss 0.004458 and acc 1.000000 \n",
      "TEST loss 0.004458 and acc 1.000000 \n",
      "Epoch 67\n",
      "TRAIN loss 0.004392 and acc 1.000000 \n",
      "TEST loss 0.004392 and acc 1.000000 \n",
      "Epoch 68\n",
      "TRAIN loss 0.004328 and acc 1.000000 \n",
      "TEST loss 0.004328 and acc 1.000000 \n",
      "Epoch 69\n",
      "TRAIN loss 0.004265 and acc 1.000000 \n",
      "TEST loss 0.004265 and acc 1.000000 \n",
      "Epoch 70\n",
      "TRAIN loss 0.004204 and acc 1.000000 \n",
      "TEST loss 0.004204 and acc 1.000000 \n",
      "Epoch 71\n",
      "TRAIN loss 0.004145 and acc 1.000000 \n",
      "TEST loss 0.004145 and acc 1.000000 \n",
      "Epoch 72\n",
      "TRAIN loss 0.004088 and acc 1.000000 \n",
      "TEST loss 0.004088 and acc 1.000000 \n",
      "Epoch 73\n",
      "TRAIN loss 0.004032 and acc 1.000000 \n",
      "TEST loss 0.004032 and acc 1.000000 \n",
      "Epoch 74\n",
      "TRAIN loss 0.003978 and acc 1.000000 \n",
      "TEST loss 0.003978 and acc 1.000000 \n",
      "Epoch 75\n",
      "TRAIN loss 0.003925 and acc 1.000000 \n",
      "TEST loss 0.003925 and acc 1.000000 \n",
      "Epoch 76\n",
      "TRAIN loss 0.003873 and acc 1.000000 \n",
      "TEST loss 0.003873 and acc 1.000000 \n",
      "Epoch 77\n",
      "TRAIN loss 0.003823 and acc 1.000000 \n",
      "TEST loss 0.003823 and acc 1.000000 \n",
      "Epoch 78\n",
      "TRAIN loss 0.003774 and acc 1.000000 \n",
      "TEST loss 0.003774 and acc 1.000000 \n",
      "Epoch 79\n",
      "TRAIN loss 0.003727 and acc 1.000000 \n",
      "TEST loss 0.003727 and acc 1.000000 \n",
      "Epoch 80\n",
      "TRAIN loss 0.003680 and acc 1.000000 \n",
      "TEST loss 0.003680 and acc 1.000000 \n",
      "Epoch 81\n",
      "TRAIN loss 0.003635 and acc 1.000000 \n",
      "TEST loss 0.003635 and acc 1.000000 \n",
      "Epoch 82\n",
      "TRAIN loss 0.003591 and acc 1.000000 \n",
      "TEST loss 0.003591 and acc 1.000000 \n",
      "Epoch 83\n",
      "TRAIN loss 0.003547 and acc 1.000000 \n",
      "TEST loss 0.003547 and acc 1.000000 \n",
      "Epoch 84\n",
      "TRAIN loss 0.003505 and acc 1.000000 \n",
      "TEST loss 0.003505 and acc 1.000000 \n",
      "Epoch 85\n",
      "TRAIN loss 0.003464 and acc 1.000000 \n",
      "TEST loss 0.003464 and acc 1.000000 \n",
      "Epoch 86\n",
      "TRAIN loss 0.003424 and acc 1.000000 \n",
      "TEST loss 0.003424 and acc 1.000000 \n",
      "Epoch 87\n",
      "TRAIN loss 0.003385 and acc 1.000000 \n",
      "TEST loss 0.003385 and acc 1.000000 \n",
      "Epoch 88\n",
      "TRAIN loss 0.003346 and acc 1.000000 \n",
      "TEST loss 0.003346 and acc 1.000000 \n",
      "Epoch 89\n",
      "TRAIN loss 0.003309 and acc 1.000000 \n",
      "TEST loss 0.003309 and acc 1.000000 \n",
      "Epoch 90\n",
      "TRAIN loss 0.003272 and acc 1.000000 \n",
      "TEST loss 0.003272 and acc 1.000000 \n",
      "Epoch 91\n",
      "TRAIN loss 0.003236 and acc 1.000000 \n",
      "TEST loss 0.003236 and acc 1.000000 \n",
      "Epoch 92\n",
      "TRAIN loss 0.003201 and acc 1.000000 \n",
      "TEST loss 0.003201 and acc 1.000000 \n",
      "Epoch 93\n",
      "TRAIN loss 0.003167 and acc 1.000000 \n",
      "TEST loss 0.003167 and acc 1.000000 \n",
      "Epoch 94\n",
      "TRAIN loss 0.003133 and acc 1.000000 \n",
      "TEST loss 0.003133 and acc 1.000000 \n",
      "Epoch 95\n",
      "TRAIN loss 0.003100 and acc 1.000000 \n",
      "TEST loss 0.003100 and acc 1.000000 \n",
      "Epoch 96\n",
      "TRAIN loss 0.003068 and acc 1.000000 \n",
      "TEST loss 0.003068 and acc 1.000000 \n",
      "Epoch 97\n",
      "TRAIN loss 0.003036 and acc 1.000000 \n",
      "TEST loss 0.003036 and acc 1.000000 \n",
      "Epoch 98\n",
      "TRAIN loss 0.003005 and acc 1.000000 \n",
      "TEST loss 0.003005 and acc 1.000000 \n",
      "Epoch 99\n",
      "TRAIN loss 0.002975 and acc 1.000000 \n",
      "TEST loss 0.002975 and acc 1.000000 \n",
      "Epoch 100\n",
      "TRAIN loss 0.002945 and acc 1.000000 \n",
      "TEST loss 0.002945 and acc 1.000000 \n",
      "Epoch 101\n",
      "TRAIN loss 0.002916 and acc 1.000000 \n",
      "TEST loss 0.002916 and acc 1.000000 \n",
      "Epoch 102\n",
      "TRAIN loss 0.002887 and acc 1.000000 \n",
      "TEST loss 0.002887 and acc 1.000000 \n",
      "Epoch 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN loss 0.002860 and acc 1.000000 \n",
      "TEST loss 0.002860 and acc 1.000000 \n",
      "Epoch 104\n",
      "TRAIN loss 0.002832 and acc 1.000000 \n",
      "TEST loss 0.002832 and acc 1.000000 \n",
      "Epoch 105\n",
      "TRAIN loss 0.002805 and acc 1.000000 \n",
      "TEST loss 0.002805 and acc 1.000000 \n",
      "Epoch 106\n",
      "TRAIN loss 0.002779 and acc 1.000000 \n",
      "TEST loss 0.002779 and acc 1.000000 \n",
      "Epoch 107\n",
      "TRAIN loss 0.002753 and acc 1.000000 \n",
      "TEST loss 0.002753 and acc 1.000000 \n",
      "Epoch 108\n",
      "TRAIN loss 0.002727 and acc 1.000000 \n",
      "TEST loss 0.002727 and acc 1.000000 \n",
      "Epoch 109\n",
      "TRAIN loss 0.002702 and acc 1.000000 \n",
      "TEST loss 0.002702 and acc 1.000000 \n",
      "Epoch 110\n",
      "TRAIN loss 0.002678 and acc 1.000000 \n",
      "TEST loss 0.002678 and acc 1.000000 \n",
      "Epoch 111\n",
      "TRAIN loss 0.002654 and acc 1.000000 \n",
      "TEST loss 0.002654 and acc 1.000000 \n",
      "Epoch 112\n",
      "TRAIN loss 0.002630 and acc 1.000000 \n",
      "TEST loss 0.002630 and acc 1.000000 \n",
      "Epoch 113\n",
      "TRAIN loss 0.002607 and acc 1.000000 \n",
      "TEST loss 0.002607 and acc 1.000000 \n",
      "Epoch 114\n",
      "TRAIN loss 0.002584 and acc 1.000000 \n",
      "TEST loss 0.002584 and acc 1.000000 \n",
      "Epoch 115\n",
      "TRAIN loss 0.002562 and acc 1.000000 \n",
      "TEST loss 0.002562 and acc 1.000000 \n",
      "Epoch 116\n",
      "TRAIN loss 0.002539 and acc 1.000000 \n",
      "TEST loss 0.002539 and acc 1.000000 \n",
      "Epoch 117\n",
      "TRAIN loss 0.002518 and acc 1.000000 \n",
      "TEST loss 0.002518 and acc 1.000000 \n",
      "Epoch 118\n",
      "TRAIN loss 0.002496 and acc 1.000000 \n",
      "TEST loss 0.002496 and acc 1.000000 \n",
      "Epoch 119\n",
      "TRAIN loss 0.002476 and acc 1.000000 \n",
      "TEST loss 0.002476 and acc 1.000000 \n",
      "Epoch 120\n",
      "TRAIN loss 0.002455 and acc 1.000000 \n",
      "TEST loss 0.002455 and acc 1.000000 \n",
      "Epoch 121\n",
      "TRAIN loss 0.002434 and acc 1.000000 \n",
      "TEST loss 0.002434 and acc 1.000000 \n",
      "Epoch 122\n",
      "TRAIN loss 0.002415 and acc 1.000000 \n",
      "TEST loss 0.002415 and acc 1.000000 \n",
      "Epoch 123\n",
      "TRAIN loss 0.002395 and acc 1.000000 \n",
      "TEST loss 0.002395 and acc 1.000000 \n",
      "Epoch 124\n",
      "TRAIN loss 0.002376 and acc 1.000000 \n",
      "TEST loss 0.002376 and acc 1.000000 \n",
      "Epoch 125\n",
      "TRAIN loss 0.002357 and acc 1.000000 \n",
      "TEST loss 0.002357 and acc 1.000000 \n",
      "Epoch 126\n",
      "TRAIN loss 0.002338 and acc 1.000000 \n",
      "TEST loss 0.002338 and acc 1.000000 \n",
      "Epoch 127\n",
      "TRAIN loss 0.002320 and acc 1.000000 \n",
      "TEST loss 0.002320 and acc 1.000000 \n",
      "Epoch 128\n",
      "TRAIN loss 0.002301 and acc 1.000000 \n",
      "TEST loss 0.002301 and acc 1.000000 \n",
      "Epoch 129\n",
      "TRAIN loss 0.002284 and acc 1.000000 \n",
      "TEST loss 0.002284 and acc 1.000000 \n",
      "Epoch 130\n",
      "TRAIN loss 0.002266 and acc 1.000000 \n",
      "TEST loss 0.002266 and acc 1.000000 \n",
      "Epoch 131\n",
      "TRAIN loss 0.002249 and acc 1.000000 \n",
      "TEST loss 0.002249 and acc 1.000000 \n",
      "Epoch 132\n",
      "TRAIN loss 0.002232 and acc 1.000000 \n",
      "TEST loss 0.002232 and acc 1.000000 \n",
      "Epoch 133\n",
      "TRAIN loss 0.002215 and acc 1.000000 \n",
      "TEST loss 0.002215 and acc 1.000000 \n",
      "Epoch 134\n",
      "TRAIN loss 0.002198 and acc 1.000000 \n",
      "TEST loss 0.002198 and acc 1.000000 \n",
      "Epoch 135\n",
      "TRAIN loss 0.002182 and acc 1.000000 \n",
      "TEST loss 0.002182 and acc 1.000000 \n",
      "Epoch 136\n",
      "TRAIN loss 0.002166 and acc 1.000000 \n",
      "TEST loss 0.002166 and acc 1.000000 \n",
      "Epoch 137\n",
      "TRAIN loss 0.002150 and acc 1.000000 \n",
      "TEST loss 0.002150 and acc 1.000000 \n",
      "Epoch 138\n",
      "TRAIN loss 0.002135 and acc 1.000000 \n",
      "TEST loss 0.002135 and acc 1.000000 \n",
      "Epoch 139\n",
      "TRAIN loss 0.002120 and acc 1.000000 \n",
      "TEST loss 0.002120 and acc 1.000000 \n",
      "Epoch 140\n",
      "TRAIN loss 0.002104 and acc 1.000000 \n",
      "TEST loss 0.002104 and acc 1.000000 \n",
      "Epoch 141\n",
      "TRAIN loss 0.002089 and acc 1.000000 \n",
      "TEST loss 0.002089 and acc 1.000000 \n",
      "Epoch 142\n",
      "TRAIN loss 0.002074 and acc 1.000000 \n",
      "TEST loss 0.002074 and acc 1.000000 \n",
      "Epoch 143\n",
      "TRAIN loss 0.002060 and acc 1.000000 \n",
      "TEST loss 0.002060 and acc 1.000000 \n",
      "Epoch 144\n",
      "TRAIN loss 0.002046 and acc 1.000000 \n",
      "TEST loss 0.002046 and acc 1.000000 \n",
      "Epoch 145\n",
      "TRAIN loss 0.002032 and acc 1.000000 \n",
      "TEST loss 0.002032 and acc 1.000000 \n",
      "Epoch 146\n",
      "TRAIN loss 0.002018 and acc 1.000000 \n",
      "TEST loss 0.002018 and acc 1.000000 \n",
      "Epoch 147\n",
      "TRAIN loss 0.002004 and acc 1.000000 \n",
      "TEST loss 0.002004 and acc 1.000000 \n",
      "Epoch 148\n",
      "TRAIN loss 0.001991 and acc 1.000000 \n",
      "TEST loss 0.001991 and acc 1.000000 \n",
      "Epoch 149\n",
      "TRAIN loss 0.001977 and acc 1.000000 \n",
      "TEST loss 0.001977 and acc 1.000000 \n",
      "Epoch 150\n",
      "TRAIN loss 0.001964 and acc 1.000000 \n",
      "TEST loss 0.001964 and acc 1.000000 \n",
      "Epoch 151\n",
      "TRAIN loss 0.001951 and acc 1.000000 \n",
      "TEST loss 0.001951 and acc 1.000000 \n",
      "Epoch 152\n",
      "TRAIN loss 0.001938 and acc 1.000000 \n",
      "TEST loss 0.001938 and acc 1.000000 \n",
      "Epoch 153\n",
      "TRAIN loss 0.001925 and acc 1.000000 \n",
      "TEST loss 0.001925 and acc 1.000000 \n",
      "Epoch 154\n",
      "TRAIN loss 0.001913 and acc 1.000000 \n",
      "TEST loss 0.001913 and acc 1.000000 \n",
      "Epoch 155\n",
      "TRAIN loss 0.001901 and acc 1.000000 \n",
      "TEST loss 0.001901 and acc 1.000000 \n",
      "Epoch 156\n",
      "TRAIN loss 0.001889 and acc 1.000000 \n",
      "TEST loss 0.001889 and acc 1.000000 \n",
      "Epoch 157\n",
      "TRAIN loss 0.001877 and acc 1.000000 \n",
      "TEST loss 0.001877 and acc 1.000000 \n",
      "Epoch 158\n",
      "TRAIN loss 0.001865 and acc 1.000000 \n",
      "TEST loss 0.001865 and acc 1.000000 \n",
      "Epoch 159\n",
      "TRAIN loss 0.001853 and acc 1.000000 \n",
      "TEST loss 0.001853 and acc 1.000000 \n",
      "Epoch 160\n",
      "TRAIN loss 0.001841 and acc 1.000000 \n",
      "TEST loss 0.001841 and acc 1.000000 \n",
      "Epoch 161\n",
      "TRAIN loss 0.001830 and acc 1.000000 \n",
      "TEST loss 0.001830 and acc 1.000000 \n",
      "Epoch 162\n",
      "TRAIN loss 0.001819 and acc 1.000000 \n",
      "TEST loss 0.001819 and acc 1.000000 \n",
      "Epoch 163\n",
      "TRAIN loss 0.001807 and acc 1.000000 \n",
      "TEST loss 0.001807 and acc 1.000000 \n",
      "Epoch 164\n",
      "TRAIN loss 0.001796 and acc 1.000000 \n",
      "TEST loss 0.001796 and acc 1.000000 \n",
      "Epoch 165\n",
      "TRAIN loss 0.001786 and acc 1.000000 \n",
      "TEST loss 0.001786 and acc 1.000000 \n",
      "Epoch 166\n",
      "TRAIN loss 0.001775 and acc 1.000000 \n",
      "TEST loss 0.001775 and acc 1.000000 \n",
      "Epoch 167\n",
      "TRAIN loss 0.001764 and acc 1.000000 \n",
      "TEST loss 0.001764 and acc 1.000000 \n",
      "Epoch 168\n",
      "TRAIN loss 0.001754 and acc 1.000000 \n",
      "TEST loss 0.001754 and acc 1.000000 \n",
      "Epoch 169\n",
      "TRAIN loss 0.001743 and acc 1.000000 \n",
      "TEST loss 0.001743 and acc 1.000000 \n",
      "Epoch 170\n",
      "TRAIN loss 0.001733 and acc 1.000000 \n",
      "TEST loss 0.001733 and acc 1.000000 \n",
      "Epoch 171\n",
      "TRAIN loss 0.001723 and acc 1.000000 \n",
      "TEST loss 0.001723 and acc 1.000000 \n",
      "Epoch 172\n",
      "TRAIN loss 0.001713 and acc 1.000000 \n",
      "TEST loss 0.001713 and acc 1.000000 \n",
      "Epoch 173\n",
      "TRAIN loss 0.001703 and acc 1.000000 \n",
      "TEST loss 0.001703 and acc 1.000000 \n",
      "Epoch 174\n",
      "TRAIN loss 0.001693 and acc 1.000000 \n",
      "TEST loss 0.001693 and acc 1.000000 \n",
      "Epoch 175\n",
      "TRAIN loss 0.001683 and acc 1.000000 \n",
      "TEST loss 0.001683 and acc 1.000000 \n",
      "Epoch 176\n",
      "TRAIN loss 0.001674 and acc 1.000000 \n",
      "TEST loss 0.001674 and acc 1.000000 \n",
      "Epoch 177\n",
      "TRAIN loss 0.001664 and acc 1.000000 \n",
      "TEST loss 0.001664 and acc 1.000000 \n",
      "Epoch 178\n",
      "TRAIN loss 0.001655 and acc 1.000000 \n",
      "TEST loss 0.001655 and acc 1.000000 \n",
      "Epoch 179\n",
      "TRAIN loss 0.001646 and acc 1.000000 \n",
      "TEST loss 0.001646 and acc 1.000000 \n",
      "Epoch 180\n",
      "TRAIN loss 0.001637 and acc 1.000000 \n",
      "TEST loss 0.001637 and acc 1.000000 \n",
      "Epoch 181\n",
      "TRAIN loss 0.001628 and acc 1.000000 \n",
      "TEST loss 0.001628 and acc 1.000000 \n",
      "Epoch 182\n",
      "TRAIN loss 0.001619 and acc 1.000000 \n",
      "TEST loss 0.001619 and acc 1.000000 \n",
      "Epoch 183\n",
      "TRAIN loss 0.001610 and acc 1.000000 \n",
      "TEST loss 0.001610 and acc 1.000000 \n",
      "Epoch 184\n",
      "TRAIN loss 0.001601 and acc 1.000000 \n",
      "TEST loss 0.001601 and acc 1.000000 \n",
      "Epoch 185\n",
      "TRAIN loss 0.001592 and acc 1.000000 \n",
      "TEST loss 0.001592 and acc 1.000000 \n",
      "Epoch 186\n",
      "TRAIN loss 0.001584 and acc 1.000000 \n",
      "TEST loss 0.001584 and acc 1.000000 \n",
      "Epoch 187\n",
      "TRAIN loss 0.001575 and acc 1.000000 \n",
      "TEST loss 0.001575 and acc 1.000000 \n",
      "Epoch 188\n",
      "TRAIN loss 0.001567 and acc 1.000000 \n",
      "TEST loss 0.001567 and acc 1.000000 \n",
      "Epoch 189\n",
      "TRAIN loss 0.001559 and acc 1.000000 \n",
      "TEST loss 0.001559 and acc 1.000000 \n",
      "Epoch 190\n",
      "TRAIN loss 0.001550 and acc 1.000000 \n",
      "TEST loss 0.001550 and acc 1.000000 \n",
      "Epoch 191\n",
      "TRAIN loss 0.001543 and acc 1.000000 \n",
      "TEST loss 0.001543 and acc 1.000000 \n",
      "Epoch 192\n",
      "TRAIN loss 0.001534 and acc 1.000000 \n",
      "TEST loss 0.001534 and acc 1.000000 \n",
      "Epoch 193\n",
      "TRAIN loss 0.001526 and acc 1.000000 \n",
      "TEST loss 0.001526 and acc 1.000000 \n",
      "Epoch 194\n",
      "TRAIN loss 0.001518 and acc 1.000000 \n",
      "TEST loss 0.001518 and acc 1.000000 \n",
      "Epoch 195\n",
      "TRAIN loss 0.001511 and acc 1.000000 \n",
      "TEST loss 0.001511 and acc 1.000000 \n",
      "Epoch 196\n",
      "TRAIN loss 0.001503 and acc 1.000000 \n",
      "TEST loss 0.001503 and acc 1.000000 \n",
      "Epoch 197\n",
      "TRAIN loss 0.001495 and acc 1.000000 \n",
      "TEST loss 0.001495 and acc 1.000000 \n",
      "Epoch 198\n",
      "TRAIN loss 0.001488 and acc 1.000000 \n",
      "TEST loss 0.001488 and acc 1.000000 \n",
      "Epoch 199\n",
      "TRAIN loss 0.001480 and acc 1.000000 \n",
      "TEST loss 0.001480 and acc 1.000000 \n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.0\n",
    "L2_DECAY = 0.0\n",
    "\n",
    "data_loader = DataReader()\n",
    "model = FNN(data_loader.inputSize(), hidden_size=300, output_size=2)\n",
    "nll_loss = nn.NLLLoss()\n",
    "op = torch.optim.SGD(model.parameters(), lr=LR, \n",
    "                     momentum=MOMENTUM, weight_decay=L2_DECAY)\n",
    "\n",
    "train_metric, test_metric = [], []\n",
    "for i in range(NUM_EPOCH):\n",
    "    print(\"Epoch %d\" % i)\n",
    "    num_batches = data_loader.init(batch_size=BATCH_SIZE)\n",
    "    model.train()\n",
    "    for b in range(num_batches):\n",
    "        x, y = data_loader.get_batch(b)\n",
    "        pred_y = model(x)\n",
    "        y = Variable(torch.from_numpy(y).long())\n",
    "        loss = nll_loss(pred_y, y)\n",
    "        op.zero_grad()\n",
    "        loss.backward()\n",
    "        op.step()\n",
    "\n",
    "    train_metric.append(eval(data_loader.train_x, data_loader.train_y, model, nll_loss, \"TRAIN\"))\n",
    "    test_metric.append(eval(data_loader.test_x, data_loader.test_y, model, nll_loss, \"TEST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
