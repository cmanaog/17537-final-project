{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import time\n",
    "import copy\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reader Class\n",
    "\n",
    "class DataReader(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        train_data = pd.read_csv(\"train.csv\", header=None)[1:]\n",
    "        \n",
    "        self.train_x = np.asarray(self.data_info.iloc[:, 0:-1])\n",
    "        self.train_y = np.asarray(self.data_info.iloc[:, -1])\n",
    "        print(\"Read %d train samples\" % len(self.train_y))\n",
    "\n",
    "        test_data = pd.read_csv(\"test.csv\", header=None)[1:]\n",
    "        \n",
    "        self.test_x = np.asarray(self.data_info.iloc[:, 0:-1])\n",
    "        self.test_y = np.asarray(self.data_info.iloc[:, -1])\n",
    "\n",
    "        print(\"Read %d test samples\" % len(self.test_y))\n",
    "\n",
    "        # get meta\n",
    "        self.num_classes = 2\n",
    "        self.input_size = self.train_x.shape[1]\n",
    "        self.indexes = list(range(len(self.train_y)))\n",
    "        self.train_size = len(self.train_y)\n",
    "        \n",
    "    def input_size(self):\n",
    "        return self.input_size\n",
    "\n",
    "    def init(self, batch_size):\n",
    "        # shuffle\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return int(math.ceil(self.train_size / float(batch_size)))\n",
    "\n",
    "    def get_batch(self, i):\n",
    "        selected_idx = self.indexes[i*self.batch_size : (i+1)*self.batch_size]\n",
    "        return self.train_x[selected_idx, :], self.train_y[selected_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        var_x = Variable(torch.from_numpy(x).float())\n",
    "        logitis = self.fc2(self.non_linear(self.fc1(var_x)))\n",
    "        return nn.functional.log_softmax(logitis, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_x, data_y, model, loss_func, name):\n",
    "    model.eval()\n",
    "    log_py = model(data_x)\n",
    "    y = Variable(torch.from_numpy(data_y).long())\n",
    "    l = loss_func(log_py, y).item()\n",
    "    \n",
    "    pred = np.argmax(log_py.data.numpy(), axis=1)\n",
    "    acc = np.mean(pred == data_y)\n",
    "    print(\"%s loss %f and acc %f \" % (name, l, acc))\n",
    "    return l, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.0\n",
    "L2_DECAY = 0.0\n",
    "\n",
    "data_loader = DataReader()\n",
    "model = FNN(data_loader.input_size(), hidden_size=300, output_size=2)\n",
    "nll_loss = nn.NLLLoss()\n",
    "op = torch.optim.SGD(model.parameters(), lr=LR, \n",
    "                     momentum=MOMENTUM, weight_decay=L2_DECAY)\n",
    "\n",
    "train_metric, test_metric = [], []\n",
    "for i in range(NUM_EPOCH):\n",
    "    print(\"Epoch %d\" % i)\n",
    "    num_batches = data_loader.init(batch_size=BATCH_SIZE)\n",
    "    model.train()\n",
    "    for b in range(num_batches):\n",
    "        x, y = data_loader.get_batch(b)\n",
    "        pred_y = model(x)\n",
    "        y = Variable(torch.from_numpy(y).long())\n",
    "        loss = nll_loss(pred_y, y)\n",
    "        op.zero_grad()\n",
    "        loss.backward()\n",
    "        op.step()\n",
    "\n",
    "    train_metric.append(eval(data_loader.train_x, data_loader.train_y, model, nll_loss, \"TRAIN\"))\n",
    "    dev_metric.append(eval(data_loader.dev_x, data_loader.dev_y, model, nll_loss, \"TEST\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
